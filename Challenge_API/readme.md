# Challenge API RAG â€” Semana 4

Este proyecto implementa una API REST basada en **FastAPI** que permite:
- Cargar documentos
- Generar embeddings semÃ¡nticos
- Realizar bÃºsquedas semÃ¡nticas
- Responder preguntas usando un enfoque **RAG (Retrieval-Augmented Generation)**

El sistema utiliza **Cohere** para embeddings y generaciÃ³n de texto, y **ChromaDB** como vector store persistente.

---

## ğŸ§± Arquitectura general

- **FastAPI**: API REST
- **Cohere**: embeddings + LLM
- **ChromaDB**: almacenamiento vectorial persistente
- **RAG**: recuperaciÃ³n de contexto + respuesta basada en documentos

Los embeddings se generan automÃ¡ticamente al indexar documentos en ChromaDB mediante una `embedding_function`.

---

## ğŸ“ Estructura del proyecto

```text
.
â”œâ”€â”€ main.py              # API principal (endpoints)
â”œâ”€â”€ schemas.py           # Modelos Pydantic (requests / responses)
â”œâ”€â”€ vectorstore.py       # ConfiguraciÃ³n de ChromaDB + embeddings Cohere
â”œâ”€â”€ llm_client.py        # Cliente Cohere
â”œâ”€â”€ llm_config.py        # Prompt del sistema y parÃ¡metros del LLM
â”œâ”€â”€ logger.py            # Logger del sistema, incompleto , no se sube a github
â”œâ”€â”€ seed_documents.py    # Script para cargar documentos desde .txt , no se sube a github
â”œâ”€â”€ data/           # Archivos .txt de ejemplo
â”œâ”€â”€ chroma_db/           # Persistencia local de ChromaDB, no se sube a github
â”œâ”€â”€ .env                 # Variables de entorno (no versionado), no se sube a github
â””â”€â”€ README.md


